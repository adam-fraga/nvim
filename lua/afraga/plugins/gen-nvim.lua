return {
	"David-Kunz/gen.nvim",
	opts = {
		model = "llama3", -- The default model to use.A
		display_mode = "split", -- The display mode. Can be "float" or "split".
		show_model = true, -- Displays which model you are using at the beginning of your chat session.
	},
}
